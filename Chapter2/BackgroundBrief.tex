\chapter{Background}
explain what this chapter will focus on from a high level - 1 paragraph

\section{AR Hardware}

\section{Perception and Depth Perception tasks in AR and VR}
A indepth look into various percepual tasks wihtin AR and VR while also looking in to various tasks in AR and VR

\section{X-ray Vision}
A in depth look into the X-ray vision field and the various tasks people can perform within it. 

\section{Volume Rendering}
This section should cover mainly Volume rendering in Human-computer interactions with 2 or 3 paragraphs dedicated to explaining some of the topics within the field.



\section {Paragraphs Removed From Intro}
Augmented reality uses are limited can be limited. 
All forms of augmented reality struggle with depth perception to some degree, even under ideal circumstances.
Some \gls{ar} displays (like \gls{ost} \gls{ar} displays) and sensors (such as infrared cameras) don't work under high amounts of exit lights as it dims the colors shown in the display and introduces inconsistent sensor readings. 
Users \glspl{SpaitalAwareness} is lessened within \acrlong{ar} \cite{Jamiy2019, Rosales2019, Al-Kalbani2019, Armbruster2008}. 
All \gls{ost} \gls{ar} require a shaded lens to properly reflect light back at the users. 
These issues don't exist as much with mobile AR~\cite{Krevelen2010}. 
\gls{ost} \gls{ar} displays also struggle to render transparent objects due to their limited color gambit~\cite{Geng2013, Xiong2021}.
But all forms of AR struggle to present objects within or behind other objects~\cite{Bajura1992, Avery2009, Kalkofen2013}.
~\cite{Parsons2021}.