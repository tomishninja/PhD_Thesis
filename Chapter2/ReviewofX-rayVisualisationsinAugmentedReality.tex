\chapter{Review of X-ray Visualisations in Augmented Reality}
\subsection{Rationale}
X-ray has been one of the first goals in Augmented reality and over the past 28 years many solutions have been developed and worked on. However, since this is such a long-lasting field of research within AR it is rapidly becoming harder to keep track of and understand the current state of research in the field.

\subsubsection{Objectives}
\begin{itemize}
    \item To determine the breadth of work done to date in X-ray vision and create an understanding of the work done throughout the field and the work left to do in the field.
    \item The technologies that have been used to create the effect of X-ray vision. 
    \item Trends the industry has been through. 
    \item How many and what X-ray visualizations have been created?
    \item Where any of these types of visualizations are tested with a specific industry in mind.
    \item What has been the most common method of verification of X-Ray visualizations that has been done to date?
    \item We also want to focus on the various experiments that have been run of X-ray vision and some details regarding to them. 
    \item We also can look at the habits of people citing each other in the field.
\end{itemize}

\subsection{Methods}
The following protocols are based on the prisma SRC\cite{Page2021} checklist.
\subsubsection{Protocol}
Prisma SRC \cite{Page2021}

\subsubsection{Eligibility Criteria}
\begin{itemize}
    \item X-Ray vision needed to be included in the study as placing virtual objects behind real-world objects.
    \item Augmented Reality needed to be included in the paper. However, the application of AR was not essential to the papers included but they did have to test theories of AR.
    \item Papers that focused on overlaying or superimposing data that would exist within a physical over real-world objects were not included.
    \item Studies that were included in multiple papers were only recorded once all papers that highlighted the same research have been included in this review as the content between both articles provides different amounts of information.
    \item If the focus on X-ray vision was light compared to other elements of the study and two or more reviewers agreed on it then the work was passed on in favor of more concise and understandable data.
\end{itemize}

\subsubsection{Information Sources}
The following databases were searched to compile for this study

\begin{itemize}
    \item ACM Digital Library
    \item IEEE Xplore
    \item Pub Med
    \item Web of Science
    \item Scopus
\end{itemize}

\subsubsection{Gray Literature}
Google Scholar - CrossRef Search

\subsection{Search Protocol}
The Ideal search terms we would have liked to be able to use would have been X-ray Vision and Augmented Reality. However, extending the search from this point seemed logical so we recursively gathered up common keywords from the various results from valid papers and used them to extend our search.
 
Due to the large field of research composing X-Ray visualizations Just the term X-ray was not included on its own unless the entry had another keyword of visualization. This was done since a generic search on X-ray and Augmented Reality would return thousands of invalid papers related to viewing medical data. 
 
The terminology of X-ray vision has been through some iterations over the years and has not always been thought of as X-ray vision so opening it up to papers that look into the perception of occlusion techniques is also important. Especially since there may also be some versions of X-ray vision originating there.
 
The second part of the search function was written to cover all of the different combinations of Augmented Reality that would return to me any field of augmented reality that would have included some form of X-ray vision. So both SAR and Augmented reality options were chosen for this search. 

This search was duplicated throughout all databases in the section. 
There were no filters applied to IEEE’s search query. 
This found us 101 search results. 
ACM’s was restricted to terms that could be found Titles Abstracts and Keywords which resulted in 40 unique results in total. 

\subsubsection{Subsequent Searches}
Two papers were also added due to being both referenced by many of our papers and being valid within our search criteria. This leads us to add these papers to our final collection of evidence. These papers could be found in the database we had chosen to use, but however, due to their age, the terminology they used made them difficult to search for other than by title. 

Papers that cited the valid papers were then found on google scholar. Any paper that had received over four citations from our initial pool of search results was then investigated. If any of these papers were valid, they would go through the same review process as the previous valid papers and if any of them were past, another cross-reference search was run to find more papers that were not previously found and could be made valid until no new papers were found.

\subsubsection{Selection of Sources of Evidence}
The evidence was first evaluated by title and abstract. If a reviewer thought the paper may have been relevant to this research, it was given a full-text read where it was they would critique if it met our eligibility criteria. It would then be independently reviewed by one other reviewer on the paper and if they agreed, it was added to the collection of evidence. 

\subsection{Data Charting}
This was done by me.

\subsection{Data Items}
From each paper I collected the following data items:
\begin{itemize}
    \item \textbf{BibTex:} Was used as a unique ID;
    \item \textbf{Title:} for ease when navigating the data;
    \item \textbf{Results Type:} What kind of research was done for this study (Case, Technical, User Evaluation or other);
    \item \textbf{AR used:} Did the paper use OSTAR or/and VSTAR or/and SAR;
    \item \textbf{Vision Classification:} stereo or mono;
    \item \textbf{Device Information:} what kind of device was used;
    \item \textbf{Technique(s):} What x-ray vision Visualizations where used in this paper;
    \item \textbf{Was first seen:} Was the techniques seen in this paper first seen here;
    \item \textbf{Ran Study:} Was a user or case study ran for this study;
    \item \textbf{Results Proven:} A brief overview of what did this paper prove;
    \item \textbf{Limitations:} What did this paper list as limitations;
    \item \textbf{Real World Use Cases:} What industry was this research aimed at.
\end{itemize}

A list of all of the papers that have cited a paper within the original database was also collected to determine the fields where the techniques are most in demand. 

\subsubsection{Data collected that was related to the user studies}
All studies that conducted user studies had the following data extracted from them where possible:
\begin{itemize}
    \item \textbf{BibTex:} Was used as a unique ID;
    \item \textbf{Amount Of Participants:} How many participants were recruited for this study;
    \item \textbf{Group Size Of Participants:} Were these participants placed into groups and how big were they;
    \item \textbf{Amount Of Independent Variables:} How many independent variables were in this study;
    \item \textbf{Numerical Breakdown Of Variables as Categories:} A breakdown of the independent variables into their classifications.
    \item \textbf{Amount Of Iterations Per Condition:} How many iterations of each set of independent variables was each user sent through.
    \item \textbf{Conditions:} A written down set of the experiments in English;
    \item \textbf{Analysis used:} What type of analysis did were used for the results;
    \item \textbf{Keywords Related To Study:} Between or within participants;
    \item \textbf{Goal Of Study:} What was the aim of the study in a word or two;
    \item \textbf{Summary Of Study:} A short written summary of the experiment;
    \item \textbf{The Distance Stimulus Was Placed:} Where were the virtual artifacts the users were expected to interact with placed;
\end{itemize}

\subsection{Results}

\begin{figure}
    \centering
    \includegraphics{Chapter2/Images/DraftOfReivewFormatForXray vision.png}
    \caption{Process for the selection of results}
    \label{fig:TheSelectionOfResultsFromLitReview}
\end{figure}

\subsection{Devices Used in X-ray vision}
The following search query was used throughout all databases it was chosen by looking at a series of key words from 20 select papers 

\textbf{Search Query:} ("X-Ray Vision" OR "X-Ray Visualization" OR ("occlusion" AND "perception") OR (Visualization AND X-ray) OR "see-through vision") AND ("AR" OR "Augmented Reality" OR "Mixed Reality" OR “SAR” OR "spatial augmented reality”)

\subsubsection{Characteristics of sources of evidence And Results of individual sources of evidence}
Notes about how various citations in the field are conducted

\textbf{Information regarding citations eg. how many times the field has been cited as a whole and within the field. What is the highest cited paper in the field.}

\subsection{Devices Used in X-ray vision}
%What type of AR devices were used.
\begin{figure}[tp]
    \centering
    \includesvg[width=\columnwidth]{Chapter2/Images/LitReviewDevicePlot.svg}
    \caption{A plot representing each paper that was published what devices it used and the type of depth cues it took into consideration. If a paper used more than one device it was counted more than two different times. }
    \label{fig:LitReviewDevices}
\end{figure}

\autoref{fig:LitReviewDevices} displays the various devices that are used throughout X-ray the various X-ray vision papers. 
Most papers that used a Head Mounted Display utilized a stereo-optic display and have been the research focus more often than any other type of display. 
\autoref{fig:LitReviewHeadsets} looks at the various headsets and the type of AR they utilize.
\gls{vst} \gls{ar} headsets are almost twice as common to see in these papers as they provided a more robust version of Augmented Reality before off-the-shelf OST AR devices like the
Microsoft HoloLens~\footnote{https://www.microsoft.com/en-us/hololens}%~\cite{microsofthololens}, 
Google Glass~\footnote{https://www.google.com.au/glass/start/}%~\cite{Glass–Gl46:online} 
or the Magic Leap~\footnote{https://www.magicleap.com/en-us/}%~\cite{MagicLeap:online}
were available.
Two papers utilized a custom OSTAR HMD for a medical purpose \cite{Bajura1992, Blum2012}.

All OSTAR devices I found were HMDs so all others in \autoref{fig:LitReviewDevices} if a device was not a HMD it was either A VST AR Device. 
The only exception to this where the SAR devices, which obviously used Spatial Augmented Reality. 
This means that a vast majority of papers in this field use VST AR devices, only eight use OST AR and three papers use SAR.

The only monitor in \autoref{fig:LitReviewDevices} that we found that used a stereoscopic display was an anaglyph method of displaying information for Augmented Reality\cite{Geethan2015}.
Mobile devices have been shown to be a popular way to showcase X-ray vision as they are an accessible method of using Augmented Reality, and several X-ray vision methods work with these systems like saliency.
X-ray vision using a \gls{sar} based system is very uncommon but has been done in medical settings and settings where the user is relatively stationary and needs an unobscured vision.


\begin{figure}[btp]
    \centering
    \includesvg[width=\columnwidth]{Chapter2/Images/LitReviewTypeOfHeadsetPlot.svg}
    \caption{A plot representing each paper that was published what type of headsets where used in each paper and weather what type of Augmented Reality they utilized.}
    \label{fig:LitReviewHeadsets}
\end{figure}




\subsection{Uses cases for X-ray vision}
% Use cases in X-ray vision
\begin{figure}[btp]
    \centering
    \includesvg[width=\columnwidth]{Chapter2/Images/LitReviewUseCasePlot.svg}
    \caption{A plot representing each published paper and its use case of note. If authors did not relate any use cases, the work was considered Generic or useful for all areas. One paper was counted twice as it fell both into the construction and driving fields.}
    \label{fig:LitReviewUseCasePlot}
\end{figure}

Most work in X-ray vision tends to look towards a more generic approach to the field. Since medicine was the first area of interest in this field, unsurprisingly, there has been a lot of interest in using this technology in this domain, and many user studies have been run here. Most of the published papers in medicine have either a case or a user study attached to them.

There is an interesting effect in the field of security where very few studies have looked into the effect of X-ray vision in the security industry published. This is likely due to this type of information being difficult to publish or the use cases that this technology is required to solve may be difficult to transfer into a user study. 

Navigation, Driving, and Education clearly benefit from having user studies run on them, leading to them having a higher than-average amount of papers providing user analysis. Interestingly the one focusing on history did not provide this type of analysis but was more concerned with demonstrating the feasibility of this type of system. 

\subsection{Types of X-Ray vision classifications}
%X-rayVisionTechnquesThatWhereComparedplot01
\begin{figure}[btp]
    \centering
    \includesvg[width=\columnwidth]{Chapter2/Images/X-rayVisionTechnquesThatWhereComparedplot01.svg}
    \caption{A heat map of the various papers that have covered various X-ray vision techniques and when they have been covered in conjunction with another study. The total sum of all papers that reference a visualization is can be found in the center of the matrix. values that are blank are combinations of various X-ray vision effects that have yet to be researched.}
    \label{fig:TypesOfX-rayVisionHeatMap}
\end{figure}

\subsubsection{Virual Hole like cues}

\textbf{Virtual hole}
The first type of X-ray vision to be done was designed by Bajura et al.~\cite{Bajura1992}. 
Which was originally used to view ultrasound data within a patient.
This method uses partial occlusion to mimic the visual sensation of looking through a box to see inside of the patient.
As seen in \autoref{fig:TypesOfX-rayVisionHeatMap}, this is the most common type of augmented reality X-ray vision technique to be used in research.

\textbf{Alpha Blending/Levels of Transparency}
It is possible to show some level of X-ray visualization just by adjusting the transparency of a physical object or the transparency of the occluded object. Sometimes this is dynamically adjusted to look more correct with the real-world viewpoint of the users. 
% Find as many citations as possible.

\textbf{Cutaways}
Cutaways present a hole through an object revealing an object on the other side of the object~\cite{Feiner1992}.
These are similar in principle to a virtual hole but require extremely good optical calibration, perfect occlusion, and some understanding of the materials that are being looked through.
Making cutaways is a common technique in graphics or virtual reality but not in augmented reality.
% more citations needed

% \textbf{Alpha Blending/Levels of Transparency}
% It is possible to show some level of X-ray visualization just by adjusting the transparency of a physical object or the openness of the occluded object. Sometimes this is dynamically adjusted to look more correct with the  

\textbf{Tunneling}
Similar to a virtual hole tunneling is an X-ray vision technology that is able to convey depth through a building or a wall to the user. 

\subsubsection{Geometric Pattern Effects}
%\textbf{Block, Grid and Wire-frame Effects}
Another way of providing X-ray vision effects is to represent the physical environment using a virtual pattern.
This is generally done in two ways. 
One way that can be done is to place a grid pattern on the ground, allowing users to retain some knowledge of depth by using a constant geometric cue~\cite{Tsuda2005, Gruenefeld2020}. 
Virtual objects may interact with this by using occlusion and/or shadows. 
Another way is to provide a virtual representation of occluding a physical object while still showing that the object is needed. This allows the augmented reality system to occlude and interact with various and allows people to see these objects. 
One method for viewing this is the wireframe effect, where a series of triangles (or quads) can be used to showcase the effect of the shape of the wall while providing some necessary occlusion.
White is a common color for this type of visualization. 

A further part of this effect has been explored by Livingston et al.~\cite{Livingston2003} who looked at the effect of using additive multiplicative color blending to extend a wireframe or grid effect to enhance the X-ray vision effect. 
They also found that this could enable them to inform the user when they were looking through more than one object by virtually representing the internal structure with the same effect.

%\textbf{Block Effect}
%This effect creates augmented quads that have a transparent shading of a particular color surrounded by a white color.

%The uses of showing occlusion by using quads. 

%\textbf{Light Grid}
%Similar to the block effect but to increase the saturation for on areas on an object where they are hit. 

\textbf{Random Dot}
Random dot is another way of expressing more occlusion than other geometric pattern effects would typically employ.
This effect provides a partial sense of occlusion by providing a semi-occlusive layer over a square shape.
This could be further emphasized. 
This should technically allow for a better sense of depth 
Highlighting various pixels on the surface of objects in order to provide a stereoscopic effect of occlusion for the user.

\textbf{Melting}
Showing an effect similar to showing parts of the occluded object and parts of the occluded object the object that needs to be viewed through. 

\subsubsection{Computer Vision Enabled Techniques}
In computer vision, there are several methods of highlighting salient features in an image.
These methods have seen prevalence in various machine computing foundations.
These effects are used commonly on VSTAR devices and work well with monoscopic environments since they can replicate elements of the image in 2D 

\textbf{Edge based}
Finding areas where there are large amounts of contrast can be found between neighboring pixels is an easy and predictable method for highlighting areas on an image.
This makes it a popular way of showcasing x-ray vision on a monoscopic AR device~\cite{Kalkofen2007, Avery2009, Sandor2010, Dey2014, Dey2012}.
By highlighting the effect of the edges of an object we are able to create the appearance that an object is behind the object either through the partial occlusion~\cite{Kalkofen2007, Avery2009} or by cutting out elements of the X-rayed object\cite{Dey2014, Dey2012}.

\textbf{Saliency}
While edge detection is one method of displaying salient features, another method may be to train an AI or write an algorithm to detect these features in a similar fashion to a human's understanding~\cite{Cong2019}.
Sandor et al.~\cite{Sandor2010} found that this could be used as a way to only display the information that a user may not expect to be able to see through and what they would expect to see through.

\textbf{Ghosting}
Ghosting is a similar effect made by Zollman et al.~\cite{Zollmann2010}. This effect utilizes perceptual grouping creating an less visually precise and more artistic effects than saliency while still following the same principles. This creates an effect that still leaves traces of the foreground image but illustrates the X-ray vision. This is in major contrast to saliency which uses a similar method to alpha blending to determine how to illustrate the position of the X-ray object, Ghosting uses a more artistic approach to this problem through the use of textures to represent various levels of saliency, Superpixels~\cite{1238308} and noise reduction algorithms~\cite{Zollmann2010}.

\textbf{Adaptive Ghosting}
Adaptive Ghosting applies a salient edge within X distance depending on salient impact from an edge with some illustrative noise~\cite{Kalkofen2013}. 
This merges all of the previous X-ray vision effects in this section to some degree. This creates a predictable X-ray vision effect but can allow for better curvature of the foreground information from a monoscopic display.

\textbf{Silhouette or Halo}
This x-ray vision effect showcases X-ray vision but just produces a halo around the object of interest if it is inside of an object and uses alpha blending to telegraph depth to the users~\cite{Ozgur2017}. 
The halo has a set size to it allowing for some help from the depth perception cue of relative size. 
This effect is designed for surgical situations and uses a monoscopic display which doesn't need to be overlaid over the area of effect as this is not common in surgical practice.
% Ozgur et al. created an effect that only uses a light amount of an X-ray vision technique that highlights the area of effect around the object to show the most effective but minimal amount of occlusion.

\textbf{P-Q Space}
An X-ray vision effect designed for volumetric rendering.
%This method can be used when applying different types of information to volumetric fields of data that may not share the same amount of realism. 
Similar to edge-based depth perception it finds regions where the depth of the image has changed dramatically on the surface body and highlights them to the end user. 
Generally, this effect lowers the realism of the model to better match the synthetic data added to it. 
Repairing the depth perception of the virtual objects in the scene without taking the real world into account. 

\subsection{Binocular Cues}
Most cues from this point moving forward have focused on monocular occlusion as it is the most powerful depth-based sense we have~\cite{Vishton1995} and these effects can potentially work on all devices. However, as mentioned previously in \autoref{Chap:Introduction} there are many more depth cues than these that can be used to demonstrate X-ray vision and may work better on more specialized devices. 

\textbf{Auxiliary Augmentation}
Shows that X-ray vision can be possible via 


This X-ray visualization shows how depth can be demonstrated through an object based on its relationship to other objects around it. 

\textbf{Vengeance Based}
Vengeance-based X-ray vision is designed to have people need change and move their focus away from the foreground to focus on the background image. 


\textbf{Multi Masking}
A proposed extension to edge-based displays that also extra information relating to the faces of objects that may also be occluded.

\subsection{A summary of User studies in X-ray Vision}
%Go over the information gathered regarding X-ray vision studies.
\textbf{Things that still need to be added:}
\begin{itemize}
    \item Details about participant information. Amounts of participants and how they were grouped creating how many random variables. Were the studies done within or between subjects?
    \item Details about the number of independent variables how they tended to break down and details about the number of repetitions
    \item Performing Questionnaires and running Anovas and T tests were the most common form of data analysis in the field. 
\end{itemize}

At the time of this research, 43 user studies have been published that have used X-ray vision.
About two-thirds (67.4\%) of the studies that were run were done within participants and one-third of them were within participants(32.5\%). %0.3255 Between -- 0.674 Within
The average amount of participants to run through a user study is $15.604$ (median $= 14$, SD $= 8.269$). 
The most any study has recited for a study is 47~\cite{Santos2013} and the minimum was a case study that only required 2 expert users for their system~\cite{Bajura1992}.


Studies tend to vary wildly in regards to independent variables with a average amount of independent variables being seen at 11.279 (medan $= 3$, SD $= 25.541$)
with the most variables existing in one study being 144 ~\cite{Livingston2003} A couple of studies only utilized a single independent variable~\cite{10.1007/978-3-540-75759-7_13, Santos2013}
This is likely due to different study designs being required for different types of studies in X-ray vision as can be seen in \autoref{fig:LitReviewStudyDesginPlot}.
3 and 4 Independent variables are the most common to find however each with 10 different studies. 

\begin{figure}[btp]
    \centering
    \includesvg[width=\columnwidth]{Chapter2/Images/LitReviewTypesOfStudiesRanplot.svg}
    \caption{This plot presents the generic types of studies and how frequently they appear in X-ray vision}
    \label{fig:LitReviewStudyDesginPlot}
\end{figure}

% What types of things are being tested with various studies
\autoref{fig:LitReviewStudyDesginPlot} shows the various types of studies that have been ran utilizing X-ray research and they are usability, depth perception, spatial awareness, and general perception of objects past the X-rayable object.
Generally the focus of many of the depth perception studies in this field has been showing that X-ray various x-ray vision effects to improve the depth perception of various effects. These studies employed similar study designed as found in other depth perception papers~\cite{Jamiy2019, Jamiy2019b}

The studies that focused on spatial awareness rather than depth perception tended to focus on a real world use case. 
These varied between understanding space in a large museum like building to trying to determine ways how to navigate a humans internal anatomy\cite{Heinrich2021, Li2016}.
The area's of usability generally investigated the use cases found in area's like medicine, construction, navigation, education and driving.

Perception utilizing X-ray vision in research generally investigated in this field to investigate the trade off between occlusion and X-ray vision~\cite{Livingston2003, Tsuda2005, Otsuki2017, Santos2016}. 
These studies looked in to how to present the various X-ray visualizations so they still provided an adequate sense of depth and resulted in a clear sense of depth.
% It would be good to stretch this out for one more sentence.


%LitReviewDistanceStudyEvaluatedplot
\begin{figure}[btp]
    \centering
    \includesvg[width=\columnwidth]{Chapter2/Images/LitReviewDistanceStudyEvaluatedplot.svg}
    \caption{This plot focuses on the distance between the user and the study subject. The ranges have been split between Vishton's and Cutting's\cite{Vishton1995} discernible depth thresholds and remote interaction for tasks when a user may have been controlling a device that was not visible to them but using X-ray vision to help aid their spatial awareness}
    \label{fig:LitReviewStudyDisernableDistancePlot}
\end{figure}

\autoref{fig:LitReviewStudyDisernableDistancePlot} shows us that most of the reseach done on X-ray vision was viewed from over 2 meters away.
With more than 25 of the studies focusing on interactions 2 - 25 meters aways from the participant this over doubles the next closet wit the near field only having 10 studies that have looked into this interaction. 
This may be due to most use cases that for X-ray vision being having better utility for interactions in the action space. Out of all of the use cases presented in \autoref{fig:LitReviewUseCasePlot} only Medical and Security really require near field interactions. 

Interestingly one study by Maia et al.~\cite{Maia2016} did look into interactions in the vista space as this is a rare space for augmented reality papers to investigate \cite{Gagnon2020}.
This paper looked into looking though various buildings to be at a distance to be able to understand what is though them.
It was not subject to many of the issues with running a depth perception study at this distance due to it's focus on usability for this task.


\subsubsection{Synthesis of results}
Talk about the risk of bias in the current studies

\subsection{Discussion}
Summery of all the results before

\section{Conclusion}
